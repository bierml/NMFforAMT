# -*- coding: utf-8 -*-
"""Music_Transcribing[NMF].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kg3AZ6yJlf2e2-mPiHodbXss7pstBQJ3

Библиотеки которые можно использовать: librosa, NMFToolbox, Nimfa, Mido/Pretty_midi,MIDIUtil.

Из всех библиотек с реализацией NMF пока остановился на Nimfa, не пойдет с ней - буду пробовать работать с NMFToolbox. Перед тем как запускать код дальше надо установить Nimfa.
"""

pip install nimfa

!grep -rl "np.mat" /usr/local/lib/python3.12/dist-packages/nimfa | xargs sed -i 's/np.mat/np.asmatrix/g'
!grep -rl "asmatrixrix" /usr/local/lib/python3.12/dist-packages/nimfa | xargs sed -i 's/asmatrixrix/asmatrix/g'
!grep -R "asmatrixrix" /usr/local/lib/python3.12/dist-packages/nimfa

"""**Читаем исходный файл**"""

from scipy.io import wavfile
import numpy as np
import librosa
import nimfa
gamma = 100
fft_bins = 2048
f_s, x = wavfile.read("/content/Prelude-in-E-Minor-Nr-4.wav")
print(f_s)        # sample rate
print(x.dtype)   # int16, int32, etc.
print(x.shape)   # (N,) mono or (N, channels)
#print(x[100000])
def init_nmf_template_pitch(K, pitch_set, freq_res, tol_pitch=0.05):
    """Initializes template matrix for a given set of pitches

    Notebook: C8/C8S3_NMFSpecFac.ipynb

    Args:
        K (int): Number of frequency points
        pitch_set (np.ndarray): Set of fundamental pitches
        freq_res (float): Frequency resolution
        tol_pitch (float): Relative frequency tolerance for the harmonics (Default value = 0.05)

    Returns:
        W (np.ndarray): Nonnegative matrix of size K x R with R = len(pitch_set)
    """
    R = len(pitch_set)
    W = np.zeros((K, R))
    for r in range(R):
        W[:, r] = template_pitch(K, pitch_set[r], freq_res, tol_pitch=tol_pitch)
    return W
def init_nmf_template_pitch_onset(K, pitch_set, freq_res, tol_pitch=0.05):
    """Initializes template matrix with onsets for a given set of pitches

    Notebook: C8/C8S3_NMFSpecFac.ipynb

    Args:
        K (int): Number of frequency points
        pitch_set (np.ndarray): Set of fundamental pitches
        freq_res (float): Frequency resolution
        tol_pitch (float): Relative frequency tolerance for the harmonics (Default value = 0.05)

    Returns:
        W (np.ndarray): Nonnegative matrix of size K x (2R) with R = len(pitch_set)
    """
    R = len(pitch_set)
    W = np.zeros((K, 2*R))
    for r in range(R):
        W[:, 2*r] = 0.1
        W[:, 2*r+1] = template_pitch(K, pitch_set[r], freq_res, tol_pitch=tol_pitch)
    return W
def template_pitch(K, pitch, freq_res, tol_pitch=0.05):
    """Defines spectral template for a given pitch

    Notebook: C8/C8S3_NMFSpecFac.ipynb

    Args:
        K (int): Number of frequency points
        pitch (float): Fundamental pitch
        freq_res (float): Frequency resolution
        tol_pitch (float): Relative frequency tolerance for the harmonics (Default value = 0.05)

    Returns:
        template (np.ndarray): Nonnegative template vector of size K
    """
    max_freq = K * freq_res
    pitch_freq = 2**((pitch - 69) / 12) * 440
    max_order = int(np.ceil(max_freq / ((1 - tol_pitch) * pitch_freq)))
    #print(max_freq,pitch_freq,max_order)
    template = np.zeros(K)
    for m in range(1, max_order + 1):
        min_idx = max(0, int((1 - tol_pitch) * m * pitch_freq / freq_res))
        max_idx = min(K-1, int((1 + tol_pitch) * m * pitch_freq / freq_res))
        template[min_idx:max_idx+1] = 1 / m
    return template

if(x.dtype==np.int32):
  x = x / (2**31)
elif(x.dtype==np.int16):
  x = x / (2**15)
else:
  raise ValueError(f"Unsupported sample type: {x.dtype}")
onsets = librosa.onset.onset_detect(y=x, sr=f_s, hop_length=1024,units='frames')
print(onsets)
spectrogram = np.abs(librosa.stft(x, n_fft=fft_bins,hop_length=1024))
spectrogram_compressed = np.log(1+gamma*spectrogram)
pitches = [x+21 for x in range(88)]
freq_res = f_s/(2 * (fft_bins//2+1))

import matplotlib.pyplot as plt
W_temp = init_nmf_template_pitch(fft_bins//2+1,pitches,freq_res)
H_temp = np.random.rand(88, spectrogram_compressed.shape[1])
#H_temp = sparse_H(H_temp,res)
#nmf = nimfa.Nmf(spectrogram_compressed, seed='fixed', W=W_temp)
nmf = nimfa.Nmf(
    spectrogram_compressed,
    rank=88,
    seed='fixed',
    W=W_temp,
    H=H_temp,
    max_iter=200,
    beta=1, sparsity=(None, 0.2)
)
nmf_fit = nmf()
W_est = nmf_fit.basis()
H_est = nmf_fit.coef()

#H_new = H_est[1::2].copy()
H_new = H_est

print(len(res))
print(type(x))
print(x.shape)
print(x.dtype)
print(np.min(x), np.max(x))
print(np.isnan(x).any(), np.isinf(x).any())

from scipy.ndimage import label
from scipy.ndimage import gaussian_filter1d
tempo, beats = librosa.beat.beat_track(y=x, sr=f_s)

tempo = float(tempo)          # or: tempo = tempo.item()

print(f"Estimated tempo: {tempo:.2f} BPM")

beat_times = librosa.frames_to_time(beats, sr=f_s)
beat_frames = list(map(int, beat_times * f_s / 1024))
print("beat_frames=",beat_frames)
print(f"Beat positions (sec.): {beat_times}")
def norm_dynamic_range(H):
  H_min = np.min(H)
  H_max = np.max(H)
  H_mean = np.mean(H)
  Z = (H-H_mean)/(H_max-H_min)
  Y = 1 / (1+np.exp(-Z))
  return Y
def top_k_indices(v, k):
    v = np.asarray(v).ravel()      # ensure 1D ndarray
    return np.argpartition(v, -k)[-k:]
def transcribe_frame(fr,thr=0.1,pol=9):
  peaks = top_k_indices(fr,20)
  notes = []
  for p in peaks:
    a = [p+12,p+19,p+24,p+28,p+31,p+34,p+36]
    notes.add((p,len(a & peaks)))

  sorted(list_of_tuples, key=lambda x: x[1])
def note_tracking(H_new,onsets,pol=6):
  H_n = H_new.copy()
  H_r = np.zeros(H_new.shape)
  #for t in onsets:
  for t in onsets:
    idx = top_k_indices(H_n[:,t],pol)
    for i in idx:
      H_r[i,t] = 1
  return H_r
def note_tracking_m(H,th=1.25):
  mean = np.mean(H)
  std = np.std(H)
  thresh = mean + th * std
  H_copy = np.zeros(H.shape)
  for i in range(H.shape[1]):
    indicies = np.where(H[:,i] > thresh)
    H_copy[indicies,i] = 1
  return H_copy
def track_notes(H):
  H_copy = np.zeros(H.shape)
  for i in range(H.shape[1]):
    indicies = np.where(H[:,i] > 0.56)
    H_copy[indicies,i] = 1
  return H_copy
def matrix_filter(H):
  H_c = H.copy()
  for i in range(H_c.shape[0]):
    for j in range(H_c.shape[1]):
      v = 0
      if ((j-1)>=0):
        v += H_c[i,j-1]
      if((j+1)<H_c.shape[1]):
        v += H_c[i,j+1]
      v += H_c[i,j]
      v = v / 3
      H_c[i,j] = v
  return H_c
def beat_sync_H(H, beat_frames, mode="mean"):
    Q, T = H.shape
    B = len(beat_frames) - 1
    H_beat = np.zeros((Q, B))

    for b in range(B):
        a, c = beat_frames[b], beat_frames[b+1]
        if mode == "mean":
            H_beat[:, b] = H[:, a:c].mean(axis=1)
        else:
            H_beat[:, b] = H[:, a:c].max(axis=1)

    return H_beat
#CONTINUE HERE
def generate_transcription(H_v,onsets):
  H_r = np.zeros(H_v.shape)
  H_m = note_tracking_m(H_v)
  mask = np.zeros(88)
  for i in range(H_v.shape[1]):
    if(i in onsets):
      H_r[:,i] = H_v[:,i]
      mask = H_v[:,i]
    else:
      H_r[:,i] = H_v[:,i] * mask
  return H_r
def finalize_transcription(H_v,H_w,onsets):
  H_r = np.zeros(H_v.shape)
  mask = np.zeros(88)
  for i in range(H_v.shape[1]):
    if(i in onsets):
      H_r[:,i] = H_v[:,i]
      mask = H_v[:,i]
    else:
      H_r[:,i] = H_w[:,i] * mask
  return H_r
def enforce_min_duration(B, min_len=5):
    for q in range(B.shape[0]):
        labels, n = label(B[q])
        for i in range(1, n+1):
            if np.sum(labels == i) < min_len:
                B[q][labels == i] = 0
    return B


def eval_hqt(H, q, t, delta=0.05):
    acc = 0.0
    count = 0
    for j in range(-10, 11):
        if 0 <= t + j < H.shape[1]:
            acc += H[q, t + j]
            count += 1
    return acc / count + delta

def rowwise_norm(H, eps=1e-8):
    Hn = H.copy()
    for q in range(H.shape[0]):
        m = np.max(Hn[q])
        if m > eps:
            Hn[q] /= m
    return Hn

#Y = norm_dynamic_range(H_new)
Y = rowwise_norm(H_new)
Y = matrix_filter(Y)
#Y = binarize_matrix(Y)
#Y = track_notes(Y)
#Y = enforce_min_duration(Y)
#Y[0,:] = 0
#H_v = np.asarray(H_v)
#H_v = beat_sync_H(H_v,beat_frames)
#print(res)

#H_v = generate_transcription(H_v,res)
#H_v = enforce_min_duration(H_v)

import matplotlib.pyplot as plt
plt.figure()
#plt.imshow(H_v, aspect='auto', origin='lower')
plt.imshow(Y[:,140:160], aspect='auto', origin='lower')
plt.colorbar()
plt.title("Activation matrix H")
plt.xlabel("Time frames")
plt.ylabel("Pitch / Component index")
plt.show()

def transcribe_frame(fr,pol=9):
  peaks = [int(p) for p in top_k_indices(fr,20)]
  notes = []
  thr = np.median(fr,axis=0)
  thr += 0.1
  print(fr.shape)
  for p in peaks:
    a = [p+12,p+19,p+24,p+28,p+31,p+34,p+36]
    if(fr[p]>thr):
      notes.append((p,float(fr[p,0]),len(set(a) & set(peaks))))
  notes = sorted(notes, key=lambda x: x[1],reverse=True)
  return notes
  print(notes)
print(transcribe_frame(Y[:,140]))
print(Y[38,203],Y[39,203])

def transcribe_frame(fr,pol=9):
  peaks = [int(p) for p in top_k_indices(fr,10)]
  notes = []
  alpha = -1
  thr = np.median(fr,axis=0)
  for p in peaks:
    a = [p+12,p+19,p+24,p+28,p+31,p+34,p+36]
    sc = 0
    for pt in range(len(a)):
      if a[pt] in peaks:
        sc += (pt+2)**alpha
    if(p > thr):
      notes.append((p,float(fr[p,0]),sc))
  notes = sorted(notes, key=lambda x: x[2],reverse=True)
  return notes
  print(notes)
print(transcribe_frame(Y[:,152]))
print(Y[38,203],Y[39,203])

print(H_v)

"""# Попробуем готовый NMFD"""

from scipy.io import wavfile
import numpy as np
import librosa
from convolutive_MM import convlutive_MM
import torch
from torchnmf.nmf import NMFD
gamma = 1
f_s, x = wavfile.read("/content/FChopinPreludeOp28n4.wav")
if(x.dtype==np.int32):
  x = x / (2**31)
elif(x.dtype==np.int16):
  x = x / (2**15)
else:
  raise ValueError(f"Unsupported sample type: {x.dtype}")
X = np.abs(librosa.stft(x, n_fft=2048,hop_length=1024))
print(f_s)        # sample rate
print(x.dtype)   # int16, int32, etc.
print(x.shape)   # (N,) mono or (N, channels)
print(x[100000])
def cnmf(V, n_components=8, n_lags=10, n_iter=100, eps=1e-9):
    """
    V: (F, T) non-negative matrix (e.g. magnitude spectrogram)
    W: (F, K, L)
    H: (K, T)
    """
    F, T = V.shape
    K = n_components
    L = n_lags

    # initialize
    W = np.random.rand(F, K, L)
    H = np.random.rand(K, T)

    for it in range(n_iter):
        print("Iteration number:",it)
        # reconstruct V_hat
        V_hat = np.zeros_like(V)
        for k in range(K):
            for l in range(L):
                V_hat[:, l:] += np.outer(W[:, k, l], H[k, :-l or None])

        # update H
        for k in range(K):
            num = np.zeros(T)
            den = np.zeros(T) + eps
            for l in range(L):
                Wkl = W[:, k, l][:, None]
                num[l:] += (Wkl * V[:, l:]).sum(axis=0)
                den[l:] += (Wkl * V_hat[:, l:]).sum(axis=0)
            H[k] *= num / den

        # update W
        for k in range(K):
            for l in range(L):
                num = (V[:, l:] * H[k, :-l or None]).sum(axis=1)
                den = (V_hat[:, l:] * H[k, :-l or None]).sum(axis=1) + eps
                W[:, k, l] *= num / den

        if it % 10 == 0:
            err = np.linalg.norm(V - V_hat)
            print(f"iter {it:3d} | error {err:.3f}")

    return W, H
#res = cnmf(X,88,10,100,eps=1e-9)
S = torch.from_numpy(X).float().unsqueeze(0)
model = NMFD(S.shape, rank=88, T=10)  # rank = components, T = time lags
model.fit(S, max_iter=200)
# Extract factors
W = model.W.detach().cpu().numpy()  # (F, rank, T)
H = model.H.detach().cpu().numpy()  # (batch, rank, time)

# Remove batch dimension from H
H = H[0]

pip install torchnmf

print(H.shape)
print(H[:,100])

import matplotlib.pyplot as plt

vmax = np.percentile(H, 99)

plt.figure(figsize=(10,4))
plt.imshow(
    H,
    aspect='auto',
    origin='lower',
    cmap='magma',
    vmin=0,
    vmax=vmax
)
plt.colorbar()
plt.title("CNMF activations (H) – clipped at 99th percentile")
plt.show()

"""# Пробуем CNMF (имплементация из libnmfd)"""

pip install libnmfd



"""# Обнаружение начал нот (Onsets detection)

Будем использовать подход, называемый Spectral Difference, вычисляя результат по формуле вот отсюда: https://www.iro.umontreal.ca/~pift6080/H09/documents/presentations/xavier_bello_tutorial.pdf
"""

def H(x):
  return (x+abs(x))/2
def summf(v1,v2):
  #v1 - spectral coefficients vector at moment n
  #v2 - spectral coefficients vector at moment (n+1)
  l = v1.shape[0]
  assert l == v2.shape[0]
  s = 0
  for i in range(l):
    s += (H(v2[i]-v1[i]))**2
  return s
def spec_diff(sp):
  res = []
  for i in range(sp.shape[1]-1):
    res.append(float(summf(sp[:,i],sp[:,i+1])))
  return res
H(5)
def eval_thrshld(d,n,M=100,abs_thrsh=0.1,lam=1.0):
  r = abs_thrsh
  n_s = n-M
  n_f = n+M
  if(n<M):
    n_s = M
  if(n+M>=len(d)):
    n_f = len(d)
  r += lam * np.median(d[n_s:n_f])
  return r
'''def peak_detect(data):
  res = np.zeros((len(data),))
  lval = 0
  for i in range(len(data)):
    if(data[i]>=eval_thrshld(data,i) and (i-lval)>=20):
      res[i] = 1
      lval = i
  return res'''
def peak_detect(data):
  #res = np.zeros((len(data),))
  res = []
  lval = 0
  for i in range(len(data)):
    if(data[i]>=eval_thrshld(data,i) and (i-lval)>=20):
      res.append(i)
      lval = i
  return res
data = spec_diff(spectrogram_compressed)
res = peak_detect(data)
def sparse_H(H,onsets):
  H_r = H.copy()
  for i in range(H_r.shape[1]):
    if(i in onsets or (i-1) in onsets or (i+1) in onsets):
      H[1::2,i] = 0
    else:
      H[0::2,i] = 0
  return H_r
print(res)
import matplotlib.pyplot as plt

import numpy as np
def shift_right(x, k):
    if(k==0):
      return x
    y = np.zeros_like(x)
    y[k:] = x[:-k]
    return y
def note_template(pitch, alpha=0.5):
  r = np.zeros((88,))
  #first eight harmonics of some pitch
  l = [0,12,19,24,28,31,34,36]
  r[l]=1
  #print(pitch)
  r = shift_right(r,pitch)
  return r
def top_k_indices(v, k):
    return np.argsort(v)[-k:][::-1]
def rms(x):
    return np.sqrt(np.mean(np.square(x)))
def process_frame(s,k=3,en_thrsh=0.4):
    assert s.shape[0] == 88 and s.shape[1] == 1
    notes = []
    s_c = s.copy()
    s_c = np.asarray(s, dtype=float).squeeze()
    #print(type(s_c))
    #print("s_c=",s_c)
    s_pitches = top_k_indices(s_c,k)
    #print("s_pitches=",s_pitches)
    for l in s_pitches:
      #print(l)
      r = rms(np.dot(note_template(l),s_c))
      #print("r=",r)
      if(r>en_thrsh):
        notes.append(int(l))
    return notes
def note_tracking(mtr):
  r = np.zeros(mtr.shape)
  for i in range(mtr.shape[1]):
    ind = process_frame(mtr[:,i])
    for k in ind:
      r[k,i] = 1
  return r

def note_tracking_paper_style(H, delta=0.1, win=10):
    Q, T = H.shape
    R = np.zeros_like(H, dtype=np.uint8)

    # 1. Per-pitch normalization (critical)
    '''keepdims=True'''
    Hn = H / (np.max(H, axis=1) + 1e-9)

    for q in range(Q):
        for t in range(T):

            # local mean (zero-padded)
            t0 = max(0, t - win)
            t1 = min(T, t + win + 1)
            local_mean = np.mean(Hn[q, t0:t1])

            # adaptive threshold
            thresh = local_mean + delta

            # onset condition (THIS is what you missed)
            if (
                Hn[q, t] > thresh and
                (t == 0 or Hn[q, t] > Hn[q, t - 1])
            ):
                R[q, t] = 1

    return R
H_n = np.log(1+H_est)
print(H_n.shape)
#H_n = note_tracking(H_n)
print(H_n.shape)
print(H_n[:,100].shape)

plt.figure()
#plt.imshow(np.log(1+200*H_est[1::2]), aspect='auto', origin='lower')
plt.imshow(note_tracking_paper_style(H_est), aspect='auto', origin='lower')
plt.colorbar()
plt.title("Activation matrix H")
plt.xlabel("Time frames")
plt.ylabel("Pitch / Component index")
plt.show()



def pitch_energy_compensation(H, gamma=0.7):
    """
    H: shape (88, T)
    """
    pitches = np.arange(88)
    weights = 2 ** (gamma * pitches / 12)
    weights = weights / weights.mean()  # normalize

    return H * weights[:, None]
H_n = np.log(1+H_est)
H_n = pitch_energy_compensation(H_n[1::2])
print(H_n.shape)
H_n = note_tracking(H_est)
print(H_n.shape)
print(H_n[:,100].shape)

plt.figure()
#plt.imshow(np.log(1+200*H_est[1::2]), aspect='auto', origin='lower')
plt.imshow(H_n, aspect='auto', origin='lower')
plt.colorbar()
plt.title("Activation matrix H")
plt.xlabel("Time frames")
plt.ylabel("Pitch / Component index")
plt.show()

print(H_s.shape)

print(note_template(0))

v=[3,7,5,2,7,8,9,1,2,3,5,6,7,8,9,2,]
def top_k_indices(v, k):
    return np.argsort(v)[-k:][::-1]
print(top_k_indices(v, 9))

"""# Оценка результатов транскрибирования"""

pip install pretty_midi

import numpy as np
import pretty_midi

def midi_to_binary_matrix(
    midi_input,
    dt=0.02,                     # time quantum in seconds
    pitch_range=(21, 108),  # A0–C8 by default
    min_overlap=0.5         # fraction of frame that must be covered
):
    """
    Convert MIDI to binary (88 x T) note activation matrix using fixed time grid.

    A note is active in a frame if it overlaps the frame
    by at least min_overlap * dt.
    """

    if dt <= 0:
        raise ValueError("dt must be positive (seconds)")

    # Load MIDI
    if isinstance(midi_input, pretty_midi.PrettyMIDI):
        pm = midi_input
    else:
        pm = pretty_midi.PrettyMIDI(midi_input)

    # Time axis
    total_time = pm.get_end_time()
    T = int(np.ceil(total_time / dt))
    frame_times = np.arange(T) * dt

    n_pitches = pitch_range[1] - pitch_range[0] + 1
    B = np.zeros((n_pitches, T), dtype=np.uint8)

    # Process notes
    for instrument in pm.instruments:
        if instrument.is_drum:
            continue

        for note in instrument.notes:
            if not (pitch_range[0] <= note.pitch <= pitch_range[1]):
                continue

            p = note.pitch - pitch_range[0]

            start_frame = int(np.floor(note.start / dt))
            end_frame   = int(np.ceil(note.end   / dt))

            for t in range(start_frame, min(end_frame, T)):
                frame_start = t * dt
                frame_end   = frame_start + dt

                overlap = max(
                    0.0,
                    min(note.end, frame_end) - max(note.start, frame_start)
                )

                if overlap >= min_overlap * dt:
                    B[p, t] = 1

    return B, frame_times

# 20 ms frames (matches typical STFT hop ~512 @ 44.1kHz)
dt = 1024 / f_s
print(dt)
B, times = midi_to_binary_matrix(
    "Prelude-in-E-Minor-Nr-4.mid",
    dt=dt
)

#print(H_v.shape, B.shape)   # (88, T)
import matplotlib.pyplot as plt
plt.figure()
#plt.imshow(H_v, aspect='auto', origin='lower')
plt.imshow(B, aspect='auto', origin='lower')
plt.colorbar()
plt.title("Activation matrix H")
plt.xlabel("Time frames")
plt.ylabel("Pitch / Component index")
plt.show()

def evaluate_results(H_et,H):
  #H_et - reference transcription of the piece
  #H - estimated transcription of the piece
  assert H_et.shape == H.shape
  P = 0
  R = 0
  F1 = 0
  TP = 0
  FP = 0
  FN = 0
  for i in range(H_et.shape[1]):
    TP += sum(1 for t, p in zip(H_et[:,i], H[:,i]) if t == 1 and p == 1)
    FP += sum(1 for t, p in zip(H_et[:,i], H[:,i]) if t == 0 and p == 1)
    FN += sum(1 for t, p in zip(H_et[:,i], H[:,i]) if t == 1 and p == 0)
  P = TP / (TP + FP)
  R = TP / (TP + FN)
  F1 = 2 * P * R / (P + R)
  return (P,R,F1)

a = [0,1,1,1,0]
b = [1,1,1,0,0]
def top_k_indices(v, k):
    v = np.asarray(v).ravel()      # ensure 1D ndarray
    return np.argpartition(v, -k)[-k:]
print(top_k_indices(b,3))

evaluate_results(H_f[:,:B.shape[1]],B)

"""Оценка результатов подхода из статьи: https://www.researchgate.net/publication/320426354_Knowledge_based_Fundamental_and_Harmonic_Frequency_Detection_in_Polyphonic_Music_Analysis"""

evaluate_results(Y[:,:B.shape[1]],B)

print(TP)